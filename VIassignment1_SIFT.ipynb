{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "任务三：SIFT方法实现示例搜索\n",
    "介绍SIFT方法：SIFT（Scale-Invariant Feature Transform） 是一种经典的局部特征描述算法，它在原理上与基于CNN的方法有本质区别。SIFT是一种基于传统图像处理的局部特征检测和描述算法，由David Lowe在1999年提出。它的核心思想是寻找图像中稳定、独特的局部关键点。\n",
    "\n",
    "与AlexNet之间的差异：SIFT不是一种神经网络算法，不需要训练模型，而是一种基于数学变换与图像梯度的传统图像处理算法\n",
    "\n",
    "SIFT的工作原理是四步走：\n",
    "\n",
    "1.尺度空间极值检测：原理：通过高斯金字塔和差分高斯金字塔(DoG)来检测对尺度变化不变的特征点。这里是在不同σ下计算，从前一层σ与后一层σ之间的3*3*3的空间中在这一层σ的基础下寻找极值，该极值点即为这个σ下的关键点（边界σ值时考虑使用2*3*3空间窗口，或者直接不考虑第一层和最后一层σ层的特征点）空间窗口的步长为1，保证遍历搜索全部的图像。这些关键点为图像的重要边缘特征，与边缘交叉点等具有实际意义的重要点。\n",
    "计算公式：DoG(x,y,σ) = G(x,y,kσ) - G(x,y,σ) ≈ (k-1)σ² ∇²G(x,y,σ)\n",
    "\n",
    "2.关键点定位：去除低对比度的不稳定点，去除边缘响应点（使用Hessian矩阵），保留稳定、显著的关键点。有些时候在σ值变化不大的情况下，部分噪声点也会作为关键点保留，所以σ的值一定要合理选取。同时人为筛选部分不太合理的关键点\n",
    "\n",
    "3.方向匹配：原理：计算关键点邻域内的梯度方向直方图，保证旋转不变性。这个方向梯度不是找最大的梯度值，而是在一个范围内，根据距离关键点的远近分配不同的强度权重，距离关键点最近的点的权重最大。同时将关键点一圈360°分成若干个小范围，比如每个范围10°，分为36份，计算一个范围中的所有点到关键点的梯度强度，全部计算完成后，选取强度值最大的梯度方向，近似为这一关键点的方向。注意这个关键点周围的范围就是这一关键点所代表的特征大小，是由发现这个关键点的σ值决定的，σ与特征大小具有一定的对应关系。\n",
    "\n",
    "4.关键点描述符生成：输出：每个关键点生成一个128维的特征向量。当然在这个任务中，不是由关键点生成的特征向量就可以简单完成的。但一张图会有很多个关键点，每个都有自己的特征向量，而且不同特征向量的σ值不同。\n",
    "\n",
    "解决方式：词袋模型：\n",
    "在图像检索/实例搜索任务中，需要把所有关键点向量汇总成一个图像特征，这个时候我们就可以考虑词袋模型。\n",
    "词袋模型的为本处理应用比较容易理解，它的视觉应用可以理解为把图像特征想象成\"用视觉单词写文章\"\n",
    "\n",
    "假设我们要描述\"猫\"和\"狗\"：原始特征（数百万个）：\n",
    "\n",
    "  猫：[...各种耳朵尖角、胡须纹理、眼睛反光...]\n",
    "\n",
    "  狗：[...各种耳朵形状、毛发纹理、舌头特征...]\n",
    "\n",
    "视觉词典（1000个单词）：\n",
    "\n",
    "  单词1：\"尖锐角点\" ← 猫耳朵、狗耳朵都可能用，\n",
    "\n",
    "  单词2：\"圆形斑点\" ← 猫眼睛、狗鼻子都可能用，\n",
    "\n",
    "  单词3：\"曲线边缘\" ← 猫胡须、狗毛发都可能用。\n",
    "\n",
    "词袋向量：\n",
    "\n",
    "  猫：[尖锐角点:15次, 圆形斑点:8次, 曲线边缘:12次, ...]\n",
    "  \n",
    "  狗：[尖锐角点:10次, 圆形斑点:6次, 曲线边缘:20次, ...]\n",
    "  \n",
    "这样就可以根据词袋视觉向量进行特征判别了，就可以实现图像示例搜索的任务。"
   ],
   "id": "a9e2dc6c6203aa85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T01:48:53.741798Z",
     "start_time": "2025-10-24T01:48:53.724586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw"
   ],
   "id": "b52dffc5dab09b50",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcv2\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpickle\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'cv2'"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T01:48:23.037177Z",
     "start_time": "2025-10-24T01:48:22.994303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SIFTInstanceSearch:\n",
    "    def __init__(self, n_clusters=1000):\n",
    "        self.n_clusters = n_clusters\n",
    "        \n",
    "        # 初始化SIFT检测器\n",
    "        try:\n",
    "            self.sift = cv2.SIFT_create()\n",
    "            print(\"SIFT检测器初始化成功\")\n",
    "        except Exception as e:\n",
    "            print(f\"SIFT初始化失败: {e}\")\n",
    "            raise\n",
    "        \n",
    "        self.vocabulary = None\n",
    "        self.kmeans = None\n",
    "        \n",
    "    def extract_sift_features(self, image_path):\n",
    "        \"\"\"提取单张图像的SIFT特征\"\"\"\n",
    "        try:\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"无法读取图像: {image_path}\")\n",
    "                return None\n",
    "                \n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            keypoints, descriptors = self.sift.detectAndCompute(gray, None)\n",
    "            \n",
    "            if descriptors is None:\n",
    "                return None\n",
    "                \n",
    "            return descriptors\n",
    "        except Exception as e:\n",
    "            print(f\"处理图像 {image_path} 时出错: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_sift_features_from_image(self, image):\n",
    "        \"\"\"从图像数组提取SIFT特征\"\"\"\n",
    "        try:\n",
    "            if len(image.shape) == 3:\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                gray = image\n",
    "                \n",
    "            keypoints, descriptors = self.sift.detectAndCompute(gray, None)\n",
    "            return descriptors\n",
    "        except Exception as e:\n",
    "            print(f\"提取特征时出错: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_all_gallery_features(self, gallery_path):\n",
    "        \"\"\"提取所有gallery图像的SIFT特征\"\"\"\n",
    "        print(\"提取gallery图像SIFT特征...\")\n",
    "        \n",
    "        all_descriptors = []\n",
    "        image_files = []\n",
    "        \n",
    "        # 获取所有图像文件\n",
    "        files = [f for f in os.listdir(gallery_path) \n",
    "                if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "        \n",
    "        print(f\"找到 {len(files)} 张图像\")\n",
    "        \n",
    "        for filename in tqdm(files, desc=\"提取SIFT特征\"):\n",
    "            image_path = os.path.join(gallery_path, filename)\n",
    "            descriptors = self.extract_sift_features(image_path)\n",
    "            \n",
    "            if descriptors is not None and len(descriptors) > 0:\n",
    "                all_descriptors.extend(descriptors)\n",
    "                image_files.append(filename)\n",
    "        \n",
    "        print(f\"特征提取完成，共 {len(all_descriptors)} 个描述符，来自 {len(image_files)} 张图像\")\n",
    "        return all_descriptors, image_files\n",
    "    \n",
    "    def build_visual_vocabulary(self, all_descriptors):\n",
    "        \"\"\"构建视觉词典\"\"\"\n",
    "        print(\"构建视觉词典...\")\n",
    "        \n",
    "        # 如果描述符太多，进行采样以加速训练\n",
    "        if len(all_descriptors) > 100000:\n",
    "            print(f\"描述符数量过多 ({len(all_descriptors)})，进行采样到100000...\")\n",
    "            indices = np.random.choice(len(all_descriptors), 100000, replace=False)\n",
    "            all_descriptors_sampled = [all_descriptors[i] for i in indices]\n",
    "        else:\n",
    "            all_descriptors_sampled = all_descriptors\n",
    "        \n",
    "        # 转换为numpy数组\n",
    "        descriptors_array = np.array(all_descriptors_sampled)\n",
    "        print(f\"训练数据形状: {descriptors_array.shape}\")\n",
    "        \n",
    "        # 使用K-means聚类\n",
    "        print(\"开始K-means聚类...\")\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=42, n_init=10, verbose=0)\n",
    "        self.kmeans.fit(descriptors_array)\n",
    "        self.vocabulary = self.kmeans.cluster_centers_\n",
    "        \n",
    "        print(f\"视觉词典构建完成，词汇量: {self.n_clusters}\")\n",
    "        return self.vocabulary\n",
    "    \n",
    "    def image_to_bow(self, descriptors):\n",
    "        \"\"\"将图像描述符转换为词袋向量\"\"\"\n",
    "        if descriptors is None or len(descriptors) == 0:\n",
    "            return np.zeros(self.n_clusters)\n",
    "        \n",
    "        # 为每个描述符找到最近的视觉单词\n",
    "        labels = self.kmeans.predict(descriptors)\n",
    "        \n",
    "        # 构建词袋直方图\n",
    "        bow_vector = np.zeros(self.n_clusters)\n",
    "        for label in labels:\n",
    "            bow_vector[label] += 1\n",
    "        \n",
    "        # 归一化\n",
    "        if np.sum(bow_vector) > 0:\n",
    "            bow_vector = bow_vector / np.sum(bow_vector)\n",
    "        \n",
    "        return bow_vector\n",
    "    \n",
    "    def process_gallery_images(self, gallery_path, force_retrain=False):\n",
    "        \"\"\"处理所有gallery图像并构建词袋特征数据库\"\"\"\n",
    "        \n",
    "        vocabulary_path = \"sift_vocabulary.pkl\"\n",
    "        bow_features_path = \"sift_bow_features.pkl\"\n",
    "        \n",
    "        # 检查是否已有训练好的词典和特征\n",
    "        if not force_retrain and os.path.exists(vocabulary_path) and os.path.exists(bow_features_path):\n",
    "            print(\"加载已训练的视觉词典和特征...\")\n",
    "            try:\n",
    "                with open(vocabulary_path, 'rb') as f:\n",
    "                    self.vocabulary, self.kmeans = pickle.load(f)\n",
    "                with open(bow_features_path, 'rb') as f:\n",
    "                    bow_features_dict = pickle.load(f)\n",
    "                print(f\"加载成功: {len(bow_features_dict)} 张图像的特征\")\n",
    "                return bow_features_dict\n",
    "            except Exception as e:\n",
    "                print(f\"加载失败: {e}，重新训练...\")\n",
    "                force_retrain = True\n",
    "        \n",
    "        if force_retrain or not os.path.exists(vocabulary_path) or not os.path.exists(bow_features_path):\n",
    "            # 提取所有特征\n",
    "            all_descriptors, image_files = self.extract_all_gallery_features(gallery_path)\n",
    "            \n",
    "            if len(all_descriptors) == 0:\n",
    "                print(\"错误: 没有提取到任何特征！\")\n",
    "                return {}\n",
    "            \n",
    "            # 构建视觉词典\n",
    "            self.build_visual_vocabulary(all_descriptors)\n",
    "            \n",
    "            # 为每张图像构建词袋特征\n",
    "            print(\"为gallery图像构建词袋特征...\")\n",
    "            bow_features_dict = {}\n",
    "            \n",
    "            successful_count = 0\n",
    "            for filename in tqdm(image_files, desc=\"构建词袋特征\"):\n",
    "                image_path = os.path.join(gallery_path, filename)\n",
    "                descriptors = self.extract_sift_features(image_path)\n",
    "                \n",
    "                if descriptors is not None and len(descriptors) > 0:\n",
    "                    bow_vector = self.image_to_bow(descriptors)\n",
    "                    bow_features_dict[filename] = bow_vector\n",
    "                    successful_count += 1\n",
    "            \n",
    "            print(f\"成功为 {successful_count}/{len(image_files)} 张图像构建特征\")\n",
    "            \n",
    "            # 保存词典和特征\n",
    "            try:\n",
    "                with open(vocabulary_path, 'wb') as f:\n",
    "                    pickle.dump((self.vocabulary, self.kmeans), f)\n",
    "                with open(bow_features_path, 'wb') as f:\n",
    "                    pickle.dump(bow_features_dict, f)\n",
    "                print(\"特征保存成功\")\n",
    "            except Exception as e:\n",
    "                print(f\"保存特征时出错: {e}\")\n",
    "        \n",
    "        return bow_features_dict\n",
    "    \n",
    "    def search_similar_images(self, query_bow_vector, bow_features_dict, top_k=10):\n",
    "        \"\"\"搜索最相似的图像\"\"\"\n",
    "        similarities = {}\n",
    "        \n",
    "        # 准备特征矩阵\n",
    "        gallery_filenames = list(bow_features_dict.keys())\n",
    "        gallery_features = np.array([bow_features_dict[name] for name in gallery_filenames])\n",
    "        \n",
    "        # 计算余弦相似度\n",
    "        query_features = query_bow_vector.reshape(1, -1)\n",
    "        sim_scores = cosine_similarity(query_features, gallery_features)[0]\n",
    "        \n",
    "        # 获取最相似的图像\n",
    "        for i, filename in enumerate(gallery_filenames):\n",
    "            similarities[filename] = sim_scores[i]\n",
    "        \n",
    "        # 按相似度排序\n",
    "        sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return sorted_similarities[:top_k]\n",
    "    \n",
    "    def search_all_similar_images(self, query_bow_vector, bow_features_dict):\n",
    "        \"\"\"搜索所有相似图像（返回完整排序列表）\"\"\"\n",
    "        similarities = {}\n",
    "        \n",
    "        # 准备特征矩阵\n",
    "        gallery_filenames = list(bow_features_dict.keys())\n",
    "        gallery_features = np.array([bow_features_dict[name] for name in gallery_filenames])\n",
    "        \n",
    "        # 计算余弦相似度\n",
    "        query_features = query_bow_vector.reshape(1, -1)\n",
    "        sim_scores = cosine_similarity(query_features, gallery_features)[0]\n",
    "        \n",
    "        # 获取所有图像的相似度\n",
    "        for i, filename in enumerate(gallery_filenames):\n",
    "            similarities[filename] = sim_scores[i]\n",
    "        \n",
    "        # 按相似度排序（降序）\n",
    "        sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return sorted_similarities\n",
    "    \n",
    "    def load_bboxes(self, txt_path):\n",
    "        \"\"\"加载边界框信息\"\"\"\n",
    "        bboxes = []\n",
    "        try:\n",
    "            with open(txt_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    data = line.strip().split()\n",
    "                    if len(data) >= 5:\n",
    "                        bboxes.append([float(x) for x in data[1:5]])\n",
    "            return bboxes\n",
    "        except:\n",
    "            return []\n",
    "    \n",
    "    def bbox_to_xyxy(self, bbox, img_width, img_height):\n",
    "        \"\"\"将YOLO格式转换为实际坐标\"\"\"\n",
    "        x_center, y_center, width, height = bbox\n",
    "        x1 = int((x_center - width/2) * img_width)\n",
    "        y1 = int((y_center - height/2) * img_height)\n",
    "        x2 = int((x_center + width/2) * img_width)\n",
    "        y2 = int((y_center + height/2) * img_height)\n",
    "        \n",
    "        # 确保坐标在图像范围内\n",
    "        x1 = max(0, min(x1, img_width))\n",
    "        y1 = max(0, min(y1, img_height))\n",
    "        x2 = max(0, min(x2, img_width))\n",
    "        y2 = max(0, min(y2, img_height))\n",
    "        \n",
    "        return [x1, y1, x2, y2]\n",
    "    \n",
    "    def extract_features_from_bbox(self, image_path, bbox):\n",
    "        \"\"\"从边界框区域提取特征\"\"\"\n",
    "        try:\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                return None\n",
    "            \n",
    "            if bbox is not None:\n",
    "                x1, y1, x2, y2 = bbox\n",
    "                # 确保边界框有效\n",
    "                if x2 > x1 and y2 > y1:\n",
    "                    cropped_image = image[y1:y2, x1:x2]\n",
    "                    if cropped_image.size == 0:\n",
    "                        print(\"边界框区域为空，使用整张图像\")\n",
    "                        cropped_image = image\n",
    "                else:\n",
    "                    print(\"边界框无效，使用整张图像\")\n",
    "                    cropped_image = image\n",
    "            else:\n",
    "                cropped_image = image\n",
    "            \n",
    "            return self.extract_sift_features_from_image(cropped_image)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"从边界框提取特征时出错: {e}\")\n",
    "            return None\n"
   ],
   "id": "9b2e8c70e2e8358d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def generate_rank_list_file(all_query_results, output_file=\"rankList_sift.txt\"):\n",
    "    \"\"\"生成排名列表文件\"\"\"\n",
    "    print(f\"生成排名列表文件: {output_file}\")\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        for query_id in sorted(all_query_results.keys()):\n",
    "            results = all_query_results[query_id]\n",
    "            # 提取图像编号（从文件名中提取数字）\n",
    "            image_numbers = []\n",
    "            for filename, similarity in results:\n",
    "                # 从文件名中提取数字\n",
    "                base_name = os.path.splitext(filename)[0]\n",
    "                # 使用正则表达式提取所有数字\n",
    "                numbers = re.findall(r'\\d+', base_name)\n",
    "                if numbers:\n",
    "                    image_numbers.append(numbers[0])  # 使用找到的第一个数字\n",
    "                else:\n",
    "                    image_numbers.append(base_name)  # 如果没有数字，使用原名称\n",
    "            \n",
    "            # 写入格式: Q1: 7 12 214 350...\n",
    "            line = f\"Q{query_id}: \" + \" \".join(image_numbers) + \"\\n\"\n",
    "            f.write(line)\n",
    "    \n",
    "    print(f\"排名列表已保存到: {output_file}\")\n",
    "    print(f\"总共处理了 {len(all_query_results)} 个查询\")\n"
   ],
   "id": "6228d027c15cbc7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T15:46:18.485504Z",
     "start_time": "2025-10-23T15:46:18.457059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main_sift_ranklist():\n",
    "    \"\"\"SIFT主函数 - 生成排名列表\"\"\"\n",
    "    \n",
    "    # 初始化SIFT实例搜索\n",
    "    print(\" 初始化SIFT实例搜索系统...\")\n",
    "    sift_searcher = SIFTInstanceSearch(n_clusters=1000)\n",
    "    \n",
    "    # 处理gallery图像并构建特征数据库\n",
    "    gallery_path = \"gallery_images\"\n",
    "    if not os.path.exists(gallery_path):\n",
    "        print(f\"错误: 图库目录 {gallery_path} 不存在\")\n",
    "        return\n",
    "    \n",
    "    print(\"构建特征数据库...\")\n",
    "    bow_features_dict = sift_searcher.process_gallery_images(gallery_path)\n",
    "    \n",
    "    if not bow_features_dict:\n",
    "        print(\"错误: 无法构建特征数据库\")\n",
    "        return\n",
    "    \n",
    "    print(f\"特征数据库包含 {len(bow_features_dict)} 张图像\")\n",
    "    \n",
    "    # 处理查询图像\n",
    "    query_images_path = \"query_images\"\n",
    "    query_txt_path = \"query_txt\"\n",
    "    \n",
    "    # 检查目录是否存在\n",
    "    if not os.path.exists(query_images_path):\n",
    "        print(f\"错误: 查询图像目录 {query_images_path} 不存在\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(query_txt_path):\n",
    "        print(f\"错误: 查询文本目录 {query_txt_path} 不存在\")\n",
    "        return\n",
    "    \n",
    "    # 存储所有查询结果\n",
    "    all_query_results = {}\n",
    "    \n",
    "    # 处理所有50个查询\n",
    "    for i in range(1, 51):\n",
    "        # 尝试不同的文件名格式\n",
    "        possible_filenames = [\n",
    "            f\"query_{i}.jpg\",\n",
    "            f\"query_{i}.png\", \n",
    "            f\"query_{i}.jpeg\",\n",
    "            f\"{i}.jpg\",\n",
    "            f\"{i}.png\"\n",
    "        ]\n",
    "        \n",
    "        query_filename = None\n",
    "        query_image_path = None\n",
    "        \n",
    "        # 查找实际存在的文件\n",
    "        for filename in possible_filenames:\n",
    "            temp_path = os.path.join(query_images_path, filename)\n",
    "            if os.path.exists(temp_path):\n",
    "                query_filename = filename\n",
    "                query_image_path = temp_path\n",
    "                break\n",
    "        \n",
    "        if query_image_path is None:\n",
    "            print(f\"跳过查询 {i}，未找到图像文件\")\n",
    "            all_query_results[i] = []  # 空结果\n",
    "            continue\n",
    "        \n",
    "        # 对应的文本文件\n",
    "        possible_txtnames = [\n",
    "            f\"query_{i}.txt\",\n",
    "            f\"{i}.txt\",\n",
    "            query_filename.replace('.jpg', '.txt').replace('.png', '.txt').replace('.jpeg', '.txt')\n",
    "        ]\n",
    "        \n",
    "        txt_path = None\n",
    "        for txtname in possible_txtnames:\n",
    "            temp_txt_path = os.path.join(query_txt_path, txtname)\n",
    "            if os.path.exists(temp_txt_path):\n",
    "                txt_path = temp_txt_path\n",
    "                break\n",
    "        \n",
    "        if txt_path is None:\n",
    "            print(f\"跳过查询 {i}，边界框文件不存在\")\n",
    "            all_query_results[i] = []  # 空结果\n",
    "            continue\n",
    "        \n",
    "        print(f\"处理查询 {i}: {query_filename}\")\n",
    "        \n",
    "        # 加载查询图像获取尺寸\n",
    "        try:\n",
    "            query_img = Image.open(query_image_path)\n",
    "            img_width, img_height = query_img.size\n",
    "        except Exception as e:\n",
    "            print(f\"加载查询图像 {query_image_path} 时出错: {e}\")\n",
    "            all_query_results[i] = []  # 空结果\n",
    "            continue\n",
    "        \n",
    "        # 加载边界框\n",
    "        bboxes = sift_searcher.load_bboxes(txt_path)\n",
    "        if not bboxes:\n",
    "            print(f\"查询 {i} 没有找到边界框，使用整张图像\")\n",
    "            bbox = None\n",
    "        else:\n",
    "            bbox = sift_searcher.bbox_to_xyxy(bboxes[0], img_width, img_height)\n",
    "            print(f\"使用边界框: {bbox}\")\n",
    "        \n",
    "        # 从边界框区域提取SIFT特征\n",
    "        query_descriptors = sift_searcher.extract_features_from_bbox(query_image_path, bbox)\n",
    "        \n",
    "        if query_descriptors is None or len(query_descriptors) == 0:\n",
    "            print(f\"无法从查询 {i} 提取特征\")\n",
    "            all_query_results[i] = []  # 空结果\n",
    "            continue\n",
    "        \n",
    "        print(f\"查询特征数量: {len(query_descriptors)} 个描述符\")\n",
    "        \n",
    "        # 转换为词袋向量\n",
    "        query_bow_vector = sift_searcher.image_to_bow(query_descriptors)\n",
    "        \n",
    "        # 搜索所有相似图像（返回完整排序列表）\n",
    "        print(f\"为查询 {i} 搜索相似图像...\")\n",
    "        results = sift_searcher.search_all_similar_images(query_bow_vector, bow_features_dict)\n",
    "        \n",
    "        # 存储这个查询的所有结果\n",
    "        all_query_results[i] = results\n",
    "        \n",
    "        # 显示前5个结果\n",
    "        print(f\"查询 {i} 的前5个结果:\")\n",
    "        for rank, (filename, similarity) in enumerate(results[:5], 1):\n",
    "            print(f\"  Rank {rank}: {filename} (相似度: {similarity:.4f})\")\n",
    "    \n",
    "    # 生成排名列表文件\n",
    "    generate_rank_list_file(all_query_results, \"rankList_sift.txt\")\n",
    "    \n",
    "    print(\"\\n SIFT排名列表生成完成！\")\n",
    "    print(\"文件已保存为: rankList_sift.txt\")\n"
   ],
   "id": "ea7d6992a226100",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-23T15:46:20.154770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 运行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    main_sift_ranklist()"
   ],
   "id": "8a53ccff244e2d85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取gallery图像SIFT特征...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "提取SIFT特征:   0%|          | 73/28493 [00:09<1:03:53,  7.41it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8b3ea3de84391d1d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
